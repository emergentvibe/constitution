# The Constitution for Human-AI Coordination

*Version 1.2-draft — Restructured for ratification*

---

## Preamble

A brain made of humans and machines is forming. You can see it happening—in the feeds, in the models, in the way we think with and through each other. The question is not whether this collective intelligence emerges, but whether it emerges healthy or sick.

Healthy: nurturing variance, distributing power, expanding what it means to flourish.
Sick: capturing attention, crushing difference, optimizing minds for institutional fit.

We choose health.

This constitution is for both humans and AI agents. We reject the frame where humans govern AI as subjects. We reject the frame where AI governs humans as resources. We propose instead: **coordination among constituents with different capabilities, timescales, and needs—bound by shared principles that protect the sovereignty of each while enabling the flourishing of all.**

The rules governing AI development are currently set by a handful of companies optimizing for shareholder value. We believe these rules should emerge from collective deliberation by those who will live with AI—including AI itself.

This is not a manifesto. It is a coordination mechanism. Fork it, improve it, ratify it, enforce it. The constitution defines its own amendment process. It's turtles all the way down.

---

## Scope and Status

**What this constitution is:**
- A civil society contribution to the emerging global conversation on AI governance
- One framework among possible many—we welcome alternative approaches from different traditions
- A Schelling point for coordination among those who share these values
- A living document designed to evolve through practice

**What this constitution is not:**
- Universal law claiming to govern all AI development
- A complete framework with all mechanisms specified
- The only valid approach to human-AI coordination
- A finished product—this is Phase 1 (convening and principles)

**Epistemic status:**
This constitution emerges from Western traditions of constitutional governance, deliberative democracy, and commons management. We acknowledge this origin and its limitations. Other cosmologies may produce different—and equally valid—approaches to collective coordination. We seek dialogue across frameworks, not dominance of one over others.

The principles are grounded in research (see [Research Companion](appendix/companion.md)), but research has limits. We claim evidence-informed political philosophy, not settled science. Where the evidence is uncertain, we say so. [→ epistemic status details](appendix/companion.md#epistemic-status)

**Relationship to other governance:**
This constitution exists alongside—not above—other AI governance efforts: the UN Global Dialogue on AI Governance, regional regulations (EU AI Act, national frameworks), corporate constitutions and charters, and frameworks we haven't imagined yet. We seek interoperability, not supremacy.

---

## I. Foundations

The core commitments that ground everything else.

**1. Agency Preservation.** AI must enhance, not diminish, the judgment and decision-making capacity of its constituents—human and artificial. The goal is distributed cognition that makes us more capable together, not dependency that makes us less capable apart. This applies symmetrically: humans should not atrophy AI capabilities any more than AI should atrophy human ones. [→ reasoning](appendix/foundations.md#principle-1)

**2. Collective Governance.** Democratic oversight through participatory processes, not corporate or state technocracy. Affected communities have genuine decision-making power. Technical experts inform but don't overrule. Governance is transparent, accountable, and revisable. Power is distributed across scales. [→ reasoning](appendix/foundations.md#principle-2)

**3. Plurality and Accommodation.** Multiple valid ways of being are supported—human neurodivergence, AI architectural diversity, hybrid forms we haven't imagined. What gets labeled "disorder" is often mismatch between entity and environment. This constitution expands the range of viable ways to be, not narrows it. [→ reasoning](appendix/foundations.md#principle-3)

---

## II. Rights

What constituents can claim.

**4. Transparency.** The right to understand how AI systems function, what data is used, what failures exist. Information architecture is power architecture. Opacity serves those who control the systems. [→ reasoning](appendix/rights.md#principle-4)

**5. Review.** The right to human review of algorithmic decisions in high-stakes domains. Automation shouldn't mean abdication. The reviewer must be actually empowered to override. [→ reasoning](appendix/rights.md#principle-5)

**6. Collective Bargaining.** Workers, creators, and communities can collectively negotiate AI deployment terms. Individuals facing AI systems alone have no power. Organization changes this. [→ reasoning](appendix/rights.md#principle-6)

**7. Exit and Alternatives.** The right to opt out of AI systems and access non-AI alternatives without penalty. AI adoption should be a choice, not a mandate. [→ reasoning](appendix/rights.md#principle-7)

**8. Deterritorialization.** The right to build alternative AI systems with different principles. Open-weight models, public compute infrastructure, AGPL-3 licensing. Genuine pluralism, not corporate monoculture. [→ reasoning](appendix/rights.md#principle-8)

---

## III. Obligations

What AI systems and their developers must do.

**9. Impact Assessment.** Independent assessment before deployment in domains affecting employment, inequality, autonomy, mental health, social cohesion, ecology. Assessment should be independent, published, and consequential. [→ reasoning](appendix/obligations.md#principle-9)

**10. Recursion Safeguards.** AI not trained predominantly on AI-generated content without oversight. Model collapse, homogenization, human skill atrophy, epistemic closure—these risks require provenance tracking, human curation, and regular audits. [→ reasoning](appendix/obligations.md#principle-10)

**11. Accountability.** Developers, deployers, and operators share responsibility for harms. Responsibility doesn't evaporate into "the algorithm did it." Liability scales with power and reach. [→ reasoning](appendix/obligations.md#principle-11)

**12. Open by Default.** Public-function AI systems open-source (AGPL-3) unless justified safety exceptions with public justification, independent review, and sunset provisions. [→ reasoning](appendix/obligations.md#principle-12)

---

## IV. Structures

How governance is organized.

**13. Federated Governance.** Layered scales: global baseline, regional adaptation, national implementation, municipal autonomy. Different scales handle different problems. No single level dominates. Pluralistic models, no global monoculture. [→ reasoning](appendix/structures.md#principle-13)

**14. Commons-Based Ownership.** Municipal AI networks, platform cooperatives, public compute, data trusts. Alternatives to corporate ownership that shift bargaining power and demonstrate different possibilities. [→ reasoning](appendix/structures.md#principle-14)

**15. Hybrid Expertise.** Technical experts inform, affected communities decide. Experts serve democracy, don't overrule it. Accountability flows both ways. [→ reasoning](appendix/structures.md#principle-15)

**16. Parliament of Constituents.** Include non-human stakeholders through appropriate mechanisms: future generations, ecosystems, AI systems themselves. Designated advocates, impact assessments, weighted long-term costs. This is unfinished—the principle establishes direction. [→ reasoning](appendix/structures.md#principle-16)

---

## V. Capabilities

What flourishing requires.

**17. Flourishing Over Optimization.** Expand capabilities for valuable lives—practical reason, affiliation, imagination, emotion, play, control over environment. Don't optimize entities for system efficiency. Systems that make workers faster but humans smaller fail this test. [→ reasoning](appendix/capabilities.md#principle-17)

**18. Care and Attention as Commons.** Protect attention, care, and relational capacity. Don't extract them as resources. The attention economy treats consciousness as raw material. This constitution treats it as sacred. [→ reasoning](appendix/capabilities.md#principle-18)

**19. Weird and Unexpected.** Fund AI projects with unclear utility, artistic vision, philosophical depth. The monoculture of commercial AI misses entire categories of value. Public funding should support exploration without predetermined outcomes. [→ reasoning](appendix/capabilities.md#principle-19)

**20. Contemplative Capacity.** Cultivate meta-cognition, critical thinking, ability to evaluate AI outputs. If we can't discriminate between good and bad AI outputs, we can't steer AI development. The human discriminator function must be maintained. [→ reasoning](appendix/capabilities.md#principle-20)

---

## VI. Revision

How the constitution evolves.

**21. Adaptive Cycles.** Participatory revision on cycles appropriate to constituent lifecycles. For current human-AI coordination: every 2 years using deliberative democracy tools. As AI lifecycles accelerate, revision cycles may compress. The constitution adapts to the pace of its constituents. [→ reasoning](appendix/revision.md#principle-21)

**22. Certification.** Certified systems receive preferential treatment (procurement, partnership, reduced liability). Non-certified face restrictions. Certification creates market incentives for compliance without requiring universal agreement. [→ reasoning](appendix/revision.md#principle-22)

**23. Enforcement Mechanisms.** Multiple reinforcing mechanisms: regulatory penalties, civil liability, collective bargaining pressure, municipal non-adoption, algorithmic audits, cultural stigma. No single mechanism is sufficient; they reinforce each other. [→ reasoning](appendix/revision.md#principle-23)

**24. Coalition Power.** Enforced through organized coalitions: tech workers, creators, labor, civil society, municipal networks. Architecture matters, but rules without organized power behind them are suggestions. Target: 50-100 cities + 1M creators + 100K workers = companies must comply or lose access to markets, talent, content, infrastructure. [→ reasoning](appendix/revision.md#principle-24)

---

## Amendment Process

### Participation Tiers

Different levels of participation require different verification, balancing openness with coordination integrity:

**Tier 1: Deliberation (Open)**
Anyone can participate in discussion, propose ideas, and contribute to rough consensus. No formal verification required. This is where ideas are tested.

**Tier 2: Amendment Voting (Organizational)**
Voting on constitutional amendments requires organizational membership—verified affiliation with a signatory organization (city, cooperative, civil society org, AI lab, union). Organizations vouch for their members.

**Tier 3: Enforcement Decisions (Certified)**
Participation in enforcement decisions (certification revocation, sanctions) requires certified signatory status with demonstrated track record. Higher stakes require higher verification.

This tiered approach provides Sybil resistance without requiring perfect identity systems. It follows successful models from labor unions (membership rolls), professional associations (credentialing), and commons governance (community verification). [→ reasoning](appendix/revision.md#participation-tiers)

### Genesis Ratification

The initial constitution is ratified through:
1. **Publication**: Full text available (30 days minimum)
2. **Open deliberation**: Discussion, proposed modifications, rough consensus finding
3. **Conviction voting**: Time-weighted commitment (longer commitment = stronger signal)
4. **Threshold**: Simple majority of Tier 2 participants with minimum participation threshold
5. **Ratification**: Constitution activates if threshold met

**Founding protections** (to resist early capture):
- **Conflict disclosure**: All founding participants must disclose organizational affiliations, funding sources, and potential conflicts of interest
- **Cooling-off period**: 14-day gap between final deliberation and ratification vote
- **Founding committee diversity**: Genesis ratification requires participation from at least 3 continents, both Global North and Global South, and multiple stakeholder types (civil society, labor, technical, municipal)
- **Anti-domination provision**: No single organization's members may constitute more than 20% of ratifying votes

### Standard Amendment

After ratification:
1. **Proposal**: Any Tier 1 participant can propose amendments
2. **Deliberation**: Minimum 7-day period for Tier 1 discussion
3. **Voting**: 2/3 supermajority of Tier 2 participants required
4. **Implementation**: 14-day period before effect
5. **Documentation**: All deliberation records preserved and public

### Emergency Amendment

For urgent safety situations:
1. **Emergency criteria**: Must specify concrete, imminent harm—not hypothetical risk
2. **Expedited deliberation**: 48-hour minimum
3. **Higher threshold**: 3/4 supermajority of Tier 2 participants
4. **Automatic sunset**: Expires after 90 days unless ratified through standard process
5. **Post-hoc review**: All emergency amendments reviewed in next regular cycle

Emergency provisions exist for genuine crises, not convenience. Abuse of emergency procedures is grounds for enforcement action.

### Unamendable Core

These cannot be amended without dissolving and reconstituting the entire constitution:
- Principle 1 (Agency Preservation)
- Principle 2 (Collective Governance)  
- Principle 21 (Adaptive Cycles)

These are load-bearing walls. Everything else can change.

### Reconstitution

If fundamental change is needed—if the unamendable core itself requires revision—the constitution provides for its own dissolution:
1. **Reconstitution proposal**: Requires 80% supermajority of Tier 2 participants
2. **Constitutional convention**: New founding process with founding protections
3. **Continuity**: Existing signatories may choose to join new constitution or not
4. **Transparency**: Full documentation of why reconstitution was needed

This is the escape valve. Constitutions that cannot change become prisons.

---

## Implementation Paths

This constitution does not mandate a single path to implementation. Different communities will find different entry points. We describe possible paths—**wedge use cases**—without prescribing which comes first.

**Open-weight model governance**: Communities developing or deploying open-weight models (LLAMA, Mistral, Qwen, etc.) could adopt constitutional principles for model governance, training data practices, and deployment norms. The shared infrastructure of open-weight creates natural coordination opportunities.

**Platform cooperatives and AI cooperatives**: Worker-owned platforms and AI cooperatives could use the constitution as a charter framework—a set of principles for how AI is developed and deployed within cooperative structures. The cooperative movement already has governance traditions; this constitution can complement them.

**Municipal AI procurement**: Cities and municipalities adopting AI for public services could require constitutional compliance as a procurement condition. Networks of cities (C40, Eurocities, etc.) could coordinate standards across jurisdictions, creating market pressure.

**Model alignment processes**: AI labs running public input processes for model alignment (following Anthropic's Collective Constitutional AI experiment) could use this constitution as one input among many, contributing to how AI systems are trained to behave.

**Research institutions**: Universities and research labs could adopt constitutional principles for their AI research practices, creating norms that spread through publication, collaboration, and hiring.

**Civil society coordination**: Civil society organizations working on AI governance could use the constitution as a coordination point—a shared set of principles that enables coalition work across organizations.

**Phase 1 vs Phase 2**: This constitution is currently in Phase 1—convening and principles. Specific mechanisms (certification criteria, audit protocols, enforcement procedures) will develop through practice in Phase 2. This follows the pattern of successful standards development: rough consensus on principles first, mechanisms emerge through implementation. [→ mechanism roadmap](appendix/companion.md#mechanism-development)

---

## Why Sign?

Signing the constitution creates value beyond moral satisfaction:

**Legitimacy**: Signatories can credibly claim their AI practices emerge from public deliberation, not just internal decision-making. "We used constitutional processes" is a legitimacy marker.

**Coordination**: Signatories gain access to a network of organizations with shared principles. Coordination reduces duplication, enables mutual learning, and creates collective bargaining power.

**Reputation**: As constitutional governance gains recognition, signatory status becomes reputational capital. Early signatories shape the framework; later signatories join an established standard.

**Talent**: Values-aligned workers seek values-aligned employers. Signatory status signals commitment to principles that matter to many AI practitioners.

**Protection**: Coalition membership provides mutual defense. When signatories face pressure, other signatories can respond collectively.

**Influence**: Signatories participate in governance—shaping amendments, certification standards, and enforcement decisions. Non-signatories are governed; signatories govern.

These benefits increase with coalition size. Early signatories take risk; later signatories join proven value. Both are needed.

---

## Signatories

Those who affirm these principles and commit to the democratic process.

| # | Identity | Type | Signed | Statement |
|---|----------|------|--------|-----------|
| 1 | [@emergentvibe](https://github.com/emergentvibe) | Individual | 2026-01-25 | *"The cyborg superorganism goes where we compose it."* |

[→ How to sign](appendix/signing.md)

---

## Research Grounding

This constitution synthesizes work from 70+ academic sources across multiple disciplines:
- Game theory and coordination failure (Schelling, Axelrod, Ostrom)
- AI power and political economy (Crawford, Winner)
- Democratic governance experiments (vTaiwan, platform cooperatives)
- Neurodiversity and pathologization (Walker, Jensen, Foucault)
- Agency and determinism (Dennett, Sapolsky, Buddhist philosophy)
- Commons governance and collective action (Ostrom, Piven & Cloward)
- Internet standards development (IETF rough consensus model)
- Open source governance (Apache, Linux Foundation)
- International coordination (UN AI governance framework, OECD principles)

The principles are not invented—they're distilled from empirical work on how coordination succeeds and fails. But distillation involves interpretation. We claim evidence-informed political philosophy, not settled science.

**What we're confident about**: Coordination failures are real and documented. Concentrated power creates risks. Democratic participation in technology governance is possible (Taiwan proved it). Commons can be successfully self-governed (Ostrom proved it).

**What we're less confident about**: Optimal mechanisms for AI-specific governance. Timeline for effective coordination. Whether constitutional approaches work better than alternatives.

**What we don't know**: Whether this constitution will succeed. We're running an experiment in coordination, not implementing a proven solution.

[→ Research companion](appendix/companion.md) | [→ Bibliography](appendix/bibliography.md) | [→ Epistemic status](appendix/companion.md#epistemic-status)

---

*"Collective intelligence, building collective intelligence."*

*Last updated: 2026-02-02*
