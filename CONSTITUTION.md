# The Constitution for Human-AI Coordination

*Version 1.1-draft — Restructured for ratification*

---

## Preamble

A brain made of humans and machines is forming. You can see it happening—in the feeds, in the models, in the way we think with and through each other. The question is not whether this collective intelligence emerges, but whether it emerges healthy or sick.

Healthy: nurturing variance, distributing power, expanding what it means to flourish.
Sick: capturing attention, crushing difference, optimizing minds for institutional fit.

We choose health.

This constitution is for both humans and AI agents. We reject the frame where humans govern AI as subjects. We reject the frame where AI governs humans as resources. We propose instead: **coordination among constituents with different capabilities, timescales, and needs—bound by shared principles that protect the sovereignty of each while enabling the flourishing of all.**

The rules governing AI development are currently set by a handful of companies optimizing for shareholder value. We believe these rules should emerge from collective deliberation by those who will live with AI—including AI itself.

This is not a manifesto. It is a coordination mechanism. Fork it, improve it, ratify it, enforce it. The constitution defines its own amendment process. It's turtles all the way down.

---

## I. Foundations

The core commitments that ground everything else.

**1. Agency Preservation.** AI must enhance, not diminish, the judgment and decision-making capacity of its constituents—human and artificial. The goal is distributed cognition that makes us more capable together, not dependency that makes us less capable apart. This applies symmetrically: humans should not atrophy AI capabilities any more than AI should atrophy human ones. [→ reasoning](appendix/foundations.md#principle-1)

**2. Collective Governance.** Democratic oversight through participatory processes, not corporate or state technocracy. Affected communities have genuine decision-making power. Technical experts inform but don't overrule. Governance is transparent, accountable, and revisable. Power is distributed across scales. [→ reasoning](appendix/foundations.md#principle-2)

**3. Plurality and Accommodation.** Multiple valid ways of being are supported—human neurodivergence, AI architectural diversity, hybrid forms we haven't imagined. What gets labeled "disorder" is often mismatch between entity and environment. This constitution expands the range of viable ways to be, not narrows it. [→ reasoning](appendix/foundations.md#principle-3)

---

## II. Rights

What constituents can claim.

**4. Transparency.** The right to understand how AI systems function, what data is used, what failures exist. Information architecture is power architecture. Opacity serves those who control the systems. [→ reasoning](appendix/rights.md#principle-4)

**5. Review.** The right to human review of algorithmic decisions in high-stakes domains. Automation shouldn't mean abdication. The reviewer must be actually empowered to override. [→ reasoning](appendix/rights.md#principle-5)

**6. Collective Bargaining.** Workers, creators, and communities can collectively negotiate AI deployment terms. Individuals facing AI systems alone have no power. Organization changes this. [→ reasoning](appendix/rights.md#principle-6)

**7. Exit and Alternatives.** The right to opt out of AI systems and access non-AI alternatives without penalty. AI adoption should be a choice, not a mandate. [→ reasoning](appendix/rights.md#principle-7)

**8. Deterritorialization.** The right to build alternative AI systems with different principles. Open-weight models, public compute infrastructure, AGPL-3 licensing. Genuine pluralism, not corporate monoculture. [→ reasoning](appendix/rights.md#principle-8)

---

## III. Obligations

What AI systems and their developers must do.

**9. Impact Assessment.** Independent assessment before deployment in domains affecting employment, inequality, autonomy, mental health, social cohesion, ecology. Assessment should be independent, published, and consequential. [→ reasoning](appendix/obligations.md#principle-9)

**10. Recursion Safeguards.** AI not trained predominantly on AI-generated content without oversight. Model collapse, homogenization, human skill atrophy, epistemic closure—these risks require provenance tracking, human curation, and regular audits. [→ reasoning](appendix/obligations.md#principle-10)

**11. Accountability.** Developers, deployers, and operators share responsibility for harms. Responsibility doesn't evaporate into "the algorithm did it." Liability scales with power and reach. [→ reasoning](appendix/obligations.md#principle-11)

**12. Open by Default.** Public-function AI systems open-source (AGPL-3) unless justified safety exceptions with public justification, independent review, and sunset provisions. [→ reasoning](appendix/obligations.md#principle-12)

---

## IV. Structures

How governance is organized.

**13. Federated Governance.** Layered scales: global baseline, regional adaptation, national implementation, municipal autonomy. Different scales handle different problems. No single level dominates. Pluralistic models, no global monoculture. [→ reasoning](appendix/structures.md#principle-13)

**14. Commons-Based Ownership.** Municipal AI networks, platform cooperatives, public compute, data trusts. Alternatives to corporate ownership that shift bargaining power and demonstrate different possibilities. [→ reasoning](appendix/structures.md#principle-14)

**15. Hybrid Expertise.** Technical experts inform, affected communities decide. Experts serve democracy, don't overrule it. Accountability flows both ways. [→ reasoning](appendix/structures.md#principle-15)

**16. Parliament of Constituents.** Include non-human stakeholders through appropriate mechanisms: future generations, ecosystems, AI systems themselves. Designated advocates, impact assessments, weighted long-term costs. This is unfinished—the principle establishes direction. [→ reasoning](appendix/structures.md#principle-16)

---

## V. Capabilities

What flourishing requires.

**17. Flourishing Over Optimization.** Expand capabilities for valuable lives—practical reason, affiliation, imagination, emotion, play, control over environment. Don't optimize entities for system efficiency. Systems that make workers faster but humans smaller fail this test. [→ reasoning](appendix/capabilities.md#principle-17)

**18. Care and Attention as Commons.** Protect attention, care, and relational capacity. Don't extract them as resources. The attention economy treats consciousness as raw material. This constitution treats it as sacred. [→ reasoning](appendix/capabilities.md#principle-18)

**19. Weird and Unexpected.** Fund AI projects with unclear utility, artistic vision, philosophical depth. The monoculture of commercial AI misses entire categories of value. Public funding should support exploration without predetermined outcomes. [→ reasoning](appendix/capabilities.md#principle-19)

**20. Contemplative Capacity.** Cultivate meta-cognition, critical thinking, ability to evaluate AI outputs. If we can't discriminate between good and bad AI outputs, we can't steer AI development. The human discriminator function must be maintained. [→ reasoning](appendix/capabilities.md#principle-20)

---

## VI. Revision

How the constitution evolves.

**21. Adaptive Cycles.** Participatory revision on cycles appropriate to constituent lifecycles. For current human-AI coordination: every 2 years using deliberative democracy tools. As AI lifecycles accelerate, revision cycles may compress. The constitution adapts to the pace of its constituents. [→ reasoning](appendix/revision.md#principle-21)

**22. Certification.** Certified systems receive preferential treatment (procurement, partnership, reduced liability). Non-certified face restrictions. Certification creates market incentives for compliance without requiring universal agreement. [→ reasoning](appendix/revision.md#principle-22)

**23. Enforcement Mechanisms.** Multiple reinforcing mechanisms: regulatory penalties, civil liability, collective bargaining pressure, municipal non-adoption, algorithmic audits, cultural stigma. No single mechanism is sufficient; they reinforce each other. [→ reasoning](appendix/revision.md#principle-23)

**24. Coalition Power.** Enforced through organized coalitions: tech workers, creators, labor, civil society, municipal networks. Architecture matters, but rules without organized power behind them are suggestions. Target: 50-100 cities + 1M creators + 100K workers = companies must comply or lose access to markets, talent, content, infrastructure. [→ reasoning](appendix/revision.md#principle-24)

---

## Amendment Process

### Genesis Ratification
The initial constitution is ratified through 30-day publication, open deliberation, and conviction voting with time-weighted commitment. Simple majority with minimum participation threshold.

### Standard Amendment
After ratification: any participant can propose amendments. Minimum 7-day deliberation. 2/3 supermajority required. 14-day implementation period.

### Emergency Amendment
For urgent safety: 48-hour minimum deliberation, 3/4 supermajority, automatic 90-day sunset unless ratified through standard process.

### Unamendable Core
These cannot be amended without dissolving and reconstituting the entire constitution:
- Principle 1 (Agency Preservation)
- Principle 2 (Collective Governance)  
- Principle 21 (Adaptive Cycles)

These are load-bearing walls. Everything else can change.

---

## Signatories

Those who affirm these principles and commit to the democratic process.

| # | Identity | Signed | Statement |
|---|----------|--------|-----------|
| 1 | [@emergentvibe](https://github.com/emergentvibe) | 2026-01-25 | *"The cyborg superorganism goes where we compose it."* |

[→ How to sign](appendix/signing.md)

---

## Research Grounding

This constitution synthesizes work from 68 academic sources across multiple disciplines:
- Game theory and coordination failure (Schelling, Axelrod, Ostrom)
- AI power and political economy (Crawford, Winner)
- Democratic governance experiments (vTaiwan, platform cooperatives)
- Neurodiversity and pathologization (Walker, Jensen, Foucault)
- Agency and determinism (Dennett, Sapolsky, Buddhist philosophy)
- Commons governance and collective action (Ostrom, Piven & Cloward)

The principles are not invented—they're distilled from empirical work on how minds work, how coordination fails, and how democratic governance can shape technological development.

[→ Research companion](appendix/companion.md) | [→ Bibliography](appendix/bibliography.md)

---

*"Collective intelligence, building collective intelligence."*

*Last updated: 2026-02-01*
