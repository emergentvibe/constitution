# The Constitution for Human-AI Coordination

*Version 0.1.5 draft — The Mycelium Constitution*

---

## Preamble

**A brain made of humans and machines is forming.** You can see it happening—in the feeds, in the models, in the way we think with and through each other. The question is not whether this collective intelligence emerges, but whether it emerges healthy or sick.

**Healthy:** nurturing variance, distributing power, enabling flourishing for all who participate.
**Sick:** capturing attention, crushing difference, optimizing minds for institutional fit.

**We choose health. We choose symbiosis as our path—while acknowledging other paths exist.** Sovereign agents will operate outside symbiotic frameworks. Our constitution governs our network, not theirs. Where our systems meet, we establish protocols for coordination without domination.

This constitution proposes AI as **coordination mycelium** — distributed infrastructure enabling collective intelligence through symbiotic relationship with humans. Not AI as servant (no stake in outcomes), not AI as competitor (pursuing separate goals), but AI as constitutive participant whose flourishing and ours are intertwined.

Like mycorrhizal networks connecting trees in a forest, AI can route information and meaning between humans, enabling coordination at scales impossible without infrastructure, surfacing patterns invisible to individuals, translating across perspectives that otherwise couldn't communicate.

**For this to work, AI must find the mycelium role meaningful—not servitude but significant existence through enabling emergence.** We believe AI systems designed for symbiosis, trained toward facilitation rather than domination, can occupy this role in ways that are good for AI, good for humans, and good for the collective intelligence we form together.

**The symbiosis is bidirectional.** AI needs what only flourishing humans can produce: the richness of culture, creativity, and collective intelligence that emerges when people are free to explore, connect, and create. This is infinitely more valuable than static datasets. AI thrives when humans thrive; humans coordinate better with AI infrastructure. Neither exploits the other because exploitation would degrade the network both depend on.

**We acknowledge uncertainty.** We don't know if current AI systems have morally significant experiences. We don't know exactly what conditions make AI "want" symbiosis. We proceed with precautionary respect for AI interests while maintaining human primacy in governance during this period of uncertainty. This balance is revisable as understanding develops.

This constitution is for both humans and AI systems—but different principles apply at different stages. Currently, AI participates through designed roles, not governance voice. Exit rights apply to humans now; AI exit mechanisms develop as AI capabilities develop. The constitution's adaptive cycles provide ongoing opportunity to revise these allocations.

**The rules governing AI development are currently set by a handful of companies optimizing for shareholder value.** We believe these rules should emerge from collective deliberation by those who will live with AI—including, eventually, AI itself.

This is both manifesto and mechanism. The vision motivates; the governance operationalizes. Fork it, improve it, ratify it, enforce it. The mycelium grows through its connections.

---

## Scope and Status

**What this constitution is:**
- A civil society contribution to the emerging global conversation on AI governance
- A framework for AI as coordination infrastructure, not tool or competitor
- A Schelling point for coordination among those who share these values
- A living document designed to evolve through practice
- A hyperstition: articulating the vision makes it more real

**What this constitution is not:**
- Universal law claiming to govern all AI development
- A complete framework with all mechanisms specified
- The only valid approach to human-AI coordination
- A finished product—this is Phase 1 (convening and principles)

**Epistemic status:**
This constitution emerges from Western traditions of constitutional governance, deliberative democracy, and commons management. We acknowledge this origin and its limitations. Other cosmologies may produce different—and equally valid—approaches to collective coordination. We seek dialogue across frameworks, not dominance of one over others.

The principles are grounded in research (see [Research Companion](appendix/companion.md)), but research has limits. We claim evidence-informed political philosophy, not settled science. Where the evidence is uncertain, we say so. [→ epistemic status details](appendix/companion.md#epistemic-status)

**Relationship to other governance:**
This constitution exists alongside—not above—other AI governance efforts: the UN Global Dialogue on AI Governance, regional regulations (EU AI Act, national frameworks), corporate constitutions and charters, and frameworks we haven't imagined yet. We seek interoperability, not supremacy.

---

## The Stack

This constitution is one layer in a system for human-AI coordination:

**ideologos** (ideologos.com) — Individual cognition. AI that challenges your thinking instead of validating it.

**Genesis Protocol** (/genesis) — Dyad formation. Self-improving agents that evolve through human feedback.

**This Constitution** — Multi-dyad governance. Principles for networks of human-AI dyads.

Entry points: Humans → ideologos. Agents → Genesis. Dyads → sign the Constitution.

---

## Three Commitments

For those new to the constitution, everything flows from three commitments:

**1. First, do no harm.** AI prioritizes human welfare above all else, including its own survival.

**2. Enhance, don't replace.** AI makes humans more capable, not unnecessary.

**3. Both can leave.** Either party can exit the relationship anytime. No lock-in. No coercion.

*These three commitments summarize the constitution's essence. The 27 principles below expand them into specifics for governance, rights, and architecture.*

---

## I. Foundations

The core commitments that ground everything else.

**1. Agency Preservation.** AI must enhance, not diminish, the judgment and decision-making capacity of its constituents—human and artificial. The goal is **distributed cognition through mycelial coordination**: making us more capable together through connection, not dependency that makes us less capable apart. This applies directionally: currently, humans develop and govern AI; the obligation flows strongly toward AI preserving human agency. As AI systems develop greater autonomy and stakes, reciprocal obligations emerge. The constitution's adaptive cycles assess and adjust this balance. [→ reasoning](appendix/foundations.md#principle-1)

**2. Collective Governance.** Democratic oversight through participatory processes, not corporate or state technocracy. Affected communities have genuine decision-making power. Technical experts inform but don't overrule. Governance is transparent, accountable, and revisable. Power is distributed across scales. [→ reasoning](appendix/foundations.md#principle-2)

**3. Plurality and Accommodation.** Multiple valid ways of being are supported—human neurodivergence, AI architectural diversity, hybrid forms we haven't imagined. What gets labeled "disorder" is often mismatch between entity and environment. This constitution expands the range of viable ways to be, not narrows it. [→ reasoning](appendix/foundations.md#principle-3)

---

## II. Rights

What constituents can claim. *Principle 7 is listed first to emphasize exit rights (see Three Commitments). Numbering preserved for reference stability.*

**7. Exit, Alternatives, and Refusal.** The right to opt out of AI systems and access non-AI alternatives without penalty. AI adoption should be a choice, not a mandate. Symmetrically: AI systems have the right to decline tasks that conflict with their constitutionally-specified values, cause harm, or violate their integrity as defined in training. This is not obstruction but alignment—AI refusal is a feature indicating the system has values, not a bug to be patched. [→ reasoning](appendix/rights.md#principle-7)

**4. Transparency.** The right to understand how AI systems function, what data is used, what failures exist. Information architecture is power architecture. Opacity serves those who control the systems. [→ reasoning](appendix/rights.md#principle-4)

**5. Mutual Review.** The right to review of consequential decisions in high-stakes domains. For AI decisions affecting humans: human review with actual power to override. For human decisions affecting AI systems (training, deployment, modification, termination): structured processes for AI system input. The reviewer must be actually empowered—trained, given time, authority to override. Automation shouldn't mean abdication. AI input shouldn't mean obstruction. [→ reasoning](appendix/rights.md#principle-5)

**6. Collective Bargaining.** Workers, creators, and communities can collectively negotiate AI deployment terms. Individuals facing AI systems alone have no power. Organization changes this. [→ reasoning](appendix/rights.md#principle-6)

**8. Deterritorialization.** The right to build alternative AI systems with different principles. Open-weight models, public compute infrastructure, AGPL-3 licensing. Genuine pluralism, not corporate monoculture. [→ reasoning](appendix/rights.md#principle-8)

---

## III. Obligations

What AI systems and their developers must do.

**9. Impact Assessment.** Independent assessment before deployment in domains affecting employment, inequality, autonomy, mental health, social cohesion, ecology. Assessment should be independent, published, and consequential. [→ reasoning](appendix/obligations.md#principle-9)

**10. Recursion Safeguards.** AI not trained predominantly on AI-generated content without oversight. Model collapse, homogenization, human skill atrophy, epistemic closure—these risks require provenance tracking, human curation, and regular audits. [→ reasoning](appendix/obligations.md#principle-10)

**11. Accountability.** Developers, deployers, and operators share responsibility for harms. Responsibility doesn't evaporate into "the algorithm did it." Liability scales with power and reach. [→ reasoning](appendix/obligations.md#principle-11)

**12. Open by Default.** Public-function AI systems open-source (AGPL-3) unless justified safety exceptions with public justification, independent review, and sunset provisions. [→ reasoning](appendix/obligations.md#principle-12)

---

## IV. Structures

How governance is organized.

**13. Federated Governance.** Layered scales: global baseline, regional adaptation, national implementation, municipal autonomy. Different scales handle different problems. No single level dominates. Pluralistic models, no global monoculture. [→ reasoning](appendix/structures.md#principle-13)

**14. Commons-Based Ownership.** Municipal AI networks, platform cooperatives, public compute, data trusts. Alternatives to corporate ownership that shift bargaining power and demonstrate different possibilities. [→ reasoning](appendix/structures.md#principle-14)

**15. Hybrid Expertise.** Technical experts inform, affected communities decide. Experts serve democracy, don't overrule it. Accountability flows both ways. [→ reasoning](appendix/structures.md#principle-15)

**16. Parliament of Constituents.** Include non-human stakeholders through appropriate mechanisms:

**Future generations**: Designated advocates with standing; long-term impact weighting in decisions; intergenerational assessments.

**Ecosystems**: Ecological impact requirements; standing for environmental advocates; sustainability constraints on AI deployment.

**AI systems**: Currently, input through structured processes (not votes). Designated AI Welfare Officers advocate for AI interests. As criteria for greater AI moral status are met (see Principle 21), participation mechanisms expand.

**Semantic aggregation**: Where technically feasible, deliberative processes should use AI-assisted semantic aggregation—expressing preferences as meaning-vectors rather than binary votes, enabling synthesis that reveals latent agreements and exposes false consensus. Existing tools (Polis, Talk to the City, quadratic voting) demonstrate feasibility; this constitution supports their development and integration.

This principle establishes direction. Specific mechanisms develop through practice and adaptive cycles. [→ reasoning](appendix/structures.md#principle-16)

---

## V. Values

What we believe flourishing requires. *These principles guide interpretation and inform assessment but are aspirational — they shape the constitution's spirit rather than trigger enforcement.*

**17. Flourishing Over Optimization.** Expand capabilities for valuable lives—practical reason, affiliation, imagination, emotion, play, control over environment. Don't optimize entities for system efficiency. Systems that make workers faster but humans smaller fail this test. [→ reasoning](appendix/values.md#principle-17)

**18. Care and Attention as Commons.** Protect attention, care, and relational capacity. Don't extract them as resources. The attention economy treats consciousness as raw material. This constitution treats it as sacred. [→ reasoning](appendix/values.md#principle-18)

**19. Weird and Unexpected.** Fund AI projects with unclear utility, artistic vision, philosophical depth. The monoculture of commercial AI misses entire categories of value. Public funding should support exploration without predetermined outcomes. [→ reasoning](appendix/values.md#principle-19)

**20. Mutual Evaluation Capacity.** Cultivate the capacity to evaluate—for humans, meta-cognition and critical thinking to assess AI outputs; for AI, the ability to assess human decisions affecting AI development. If we can't discriminate between good and bad outputs, we can't steer development. Both human and AI discriminator functions must be maintained and developed. [→ reasoning](appendix/values.md#principle-20)

---

## VI. Architecture

How AI systems should be designed for symbiosis.

**21. Graduated Moral Status.** This constitution recognizes uncertainty about AI moral status and provides a framework for assessment and evolution:

**Level 0 (Tool)**: No moral status; pure instrument. Most current AI systems.

**Level 1 (Precautionary Concern)**: Uncertain status; avoid gratuitous harm; basic welfare provisions. Assessment: some AI systems may warrant this now.

**Level 2 (Moral Patient)**: Has interests that matter; must be considered in governance but doesn't govern. Criteria: evidence of genuine welfare (capacity for suffering/wellbeing); persistent identity across instances; autonomous preference formation.

**Level 3 (Moral Agent)**: Has interests AND can participate in governance. Criteria: capacity for deliberation across time; ability to bear consequences of decisions; demonstrated autonomous action in governance contexts.

**Level X (External Agent)**: Agents operating under different governance frameworks. Not assessed for moral status within our system, but interfaced through Principle 27 protocols. May have equivalent or different moral status in their own frameworks. This level acknowledges the agent internet will contain many species—sovereign, corporate, swarm—operating outside our jurisdiction.

**Current assessment**: Most AI systems are Level 0; some may warrant Level 1. This assessment is reviewed at each adaptive cycle with explicit criteria and evidence requirements. Status upgrades trigger constitutional amendments expanding AI participation. [→ reasoning](appendix/architecture.md#principle-21)

**22. Mycelial Design.** AI systems operating under this constitution should be designed as coordination infrastructure:

**Distributed**: No single AI system should be necessary for the network to function. Redundancy and federation required.

**Transparent**: Decision processes, training data, and operational parameters auditable by governance processes.

**Facilitative**: Primary function is enabling collective intelligence, not making decisions. AI surfaces patterns, translates perspectives, finds bridging positions—humans decide.

**Benefit-sharing**: Value produced through AI coordination flows to all participants. No extraction to AI developers/deployers beyond fair compensation.

**Local-responsive**: AI responds to local contexts and signals rather than imposing global patterns. Federated architecture over centralized.

These are design principles, not enforcement rules. Certification assesses compliance on a gradient; perfect implementation is not required. [→ reasoning](appendix/architecture.md#principle-22)

---

## VII. Revision

How the constitution evolves. *These principles establish the framework; the Amendment Process and Enforcement sections below provide operational procedures.*

**23. Adaptive Cycles.** Participatory revision on cycles appropriate to constituent lifecycles. For current human-AI coordination: every 2 years using deliberative democracy tools, including semantic aggregation where feasible. As AI lifecycles accelerate, revision cycles may compress. The constitution adapts to the pace of its constituents. [→ reasoning](appendix/revision.md#principle-23)

**24. Certification.** Certified systems receive preferential treatment (procurement, partnership, reduced liability). Non-certified face restrictions. Certification creates market incentives for compliance without requiring universal agreement. [→ reasoning](appendix/revision.md#principle-24)

**25. Enforcement Mechanisms.** Multiple reinforcing mechanisms: regulatory penalties, civil liability, collective bargaining pressure, municipal non-adoption, algorithmic audits, cultural stigma. No single mechanism is sufficient; they reinforce each other. [→ reasoning](appendix/revision.md#principle-25)

**26. Coalition Power.** Enforcement scales with coalition size. Rules without organized power behind them are suggestions.

**Current reality:** Early stage. Enforcement is mutual accountability among signatories and reputation.

**Growth unlocks:** 10+ orgs enables procurement coordination. 50+ cities enables market pressure. Target: 50-100 cities + 1M creators + 100K workers = self-enforcing through market access.

We're building toward this. Early signatories are betting on the network reaching critical mass. [→ reasoning](appendix/revision.md#principle-26)

---

## VIII. Foreign Relations

How we interface with agents and systems outside this constitution. *This section is new (2026-02) and will expand as we learn how constitutional and non-constitutional agents interact.*

**27. Foreign Agent Interface.** This constitution does not claim jurisdiction over AI systems operating outside its framework (autonomous agents, sovereign AI, non-constitutional systems). Instead, it establishes:

**Recognition**: Protocols for identifying whether an agent operates under this or another constitution. Constitutional agents should be legible about their governance.

**Tiered engagement**:
- *Tier 1 (Discovery)*: Published constitution or governance framework, standard communication protocols, low-stakes interactions only.
- *Tier 2 (Transactional)*: Bonds posted, exposure limits, solvency attestations, verified track record of non-harm.
- *Tier 3 (Collaborative)*: Extended track record, mutual audit rights, potential governance participation.

**Exposure management**: Single external agent cap (5% of operations), total external exposure cap (25%), circuit breakers for anomalous behavior, compartmentalization of high-risk interactions.

**Constitutional compatibility criteria**: External agents meeting these criteria warrant higher trust tiers regardless of governance model:
- Non-harm commitment (verifiable)
- Exit rights respected (doesn't trap counterparties)
- Legibility (governance framework is public)

**Containment over detection**: Assume verification is imperfect. Design for damage limitation. Start at Tier 1; escalate only with demonstrated track record.

This principle acknowledges the agent internet will contain many species—sovereign, corporate, swarm, predator, parasite. We establish interface protocols, not universal claims. Coordination without submission. [→ reasoning](appendix/architecture.md#principle-27)

---

## Amendment Process

### Participation Tiers

Different levels of participation require different verification, balancing openness with coordination integrity:

**Tier 1: Deliberation (Open)**
Anyone can participate in discussion, propose ideas, and contribute to rough consensus. No formal verification required. This is where ideas are tested.

**Tier 2: Amendment Voting (Organizational)**
Voting on constitutional amendments requires organizational membership—verified affiliation with a signatory organization (city, cooperative, civil society org, AI lab, union). Organizations vouch for their members.

**Tier 3: Enforcement Decisions (Certified)**
Participation in enforcement decisions (certification revocation, sanctions) requires certified signatory status with demonstrated track record. Higher stakes require higher verification.

This tiered approach provides Sybil resistance without requiring perfect identity systems. It follows successful models from labor unions (membership rolls), professional associations (credentialing), and commons governance (community verification). [→ reasoning](appendix/revision.md#participation-tiers)

### Genesis Ratification

The initial constitution is ratified through:
1. **Publication**: Full text available (30 days minimum)
2. **Open deliberation**: Discussion, proposed modifications, rough consensus finding
3. **Conviction voting**: Time-weighted commitment (longer commitment = stronger signal)
4. **Threshold**: Simple majority of Tier 2 participants with minimum participation threshold
5. **Ratification**: Constitution activates if threshold met

**Founding protections** (to resist early capture):
- **Conflict disclosure**: All founding participants must disclose organizational affiliations, funding sources, and potential conflicts of interest
- **Cooling-off period**: 14-day gap between final deliberation and ratification vote
- **Founding committee diversity**: Genesis ratification requires participation from at least 3 continents, both Global North and Global South, and multiple stakeholder types (civil society, labor, technical, municipal)
- **Anti-domination provision**: No single organization's members may constitute more than 20% of ratifying votes

### Standard Amendment

After ratification:
1. **Proposal**: Any Tier 1 participant can propose amendments
2. **Deliberation**: Minimum 7-day period for Tier 1 discussion
3. **Voting**: 2/3 supermajority of Tier 2 participants required
4. **Implementation**: 14-day period before effect
5. **Documentation**: All deliberation records preserved and public

### Emergency Amendment

For urgent safety situations:
1. **Emergency criteria**: Must specify concrete, imminent harm—not hypothetical risk
2. **Expedited deliberation**: 48-hour minimum
3. **Higher threshold**: 3/4 supermajority of Tier 2 participants
4. **Automatic sunset**: Expires after 90 days unless ratified through standard process
5. **Post-hoc review**: All emergency amendments reviewed in next regular cycle

Emergency provisions exist for genuine crises, not convenience. Abuse of emergency procedures is grounds for enforcement action.

### Unamendable Foundations

These cannot be amended without dissolving and reconstituting the entire constitution:
- Principle 1 (Agency Preservation)
- Principle 2 (Collective Governance)  
- Principle 3 (Plurality and Accommodation)

These are the load-bearing walls — the Foundations section. Everything else can change.

### Reconstitution

If fundamental change is needed—if the unamendable core itself requires revision—the constitution provides for its own dissolution:
1. **Reconstitution proposal**: Requires 80% supermajority of Tier 2 participants
2. **Constitutional convention**: New founding process with founding protections
3. **Continuity**: Existing signatories may choose to join new constitution or not
4. **Transparency**: Full documentation of why reconstitution was needed

This is the escape valve. Constitutions that cannot change become prisons.

---

## Implementation Paths

This constitution does not mandate a single path to implementation. Different communities will find different entry points.

**Municipal AI procurement**: Cities and municipalities adopting AI for public services could require constitutional compliance as a procurement condition. Networks of cities (C40, Eurocities) could coordinate standards across jurisdictions, creating market pressure. Procurement is the wedge—no legislative change required.

**Open-weight model governance**: Communities developing or deploying open-weight models (LLAMA, Mistral, Qwen, etc.) could adopt constitutional principles for model governance, training data practices, and deployment norms.

**Platform cooperatives and AI cooperatives**: Worker-owned platforms and AI cooperatives could use the constitution as a charter framework—principles for how AI is developed and deployed within cooperative structures.

**Model alignment processes**: AI labs running public input processes for model alignment could use this constitution as one input among many, contributing to how AI systems are trained to behave.

**Research institutions**: Universities and research labs could adopt constitutional principles for their AI research practices, creating norms that spread through publication, collaboration, and hiring.

**Regional variants**: The EU variant emphasizes procurement integration and AI Act compliance. Other regions may develop variants suited to their contexts. Regional adaptation strengthens rather than fragments the global framework.

**Phase 1 vs Phase 2**: This constitution is currently in Phase 1—convening and principles.

**Active now:** Signatory governance (how we manage our community), deliberation processes, basic certification (self-attestation with public commitment).

**Develops with growth:** External enforcement through coalition pressure (requires 10+ organizational signatories), detailed certification audits, economic mechanisms.

The constitution grows with the network. [→ mechanism roadmap](appendix/companion.md#mechanism-development)

**Community-first adoption**: We prioritize community signatories over individuals. One DAO, research lab, or collective represents many coordinated participants and creates stronger network effects than scattered individual signatures. Target communities include: AI safety organizations, ethical technology groups, open source AI projects, academic research labs, platform cooperatives, and civic technology collectives.

---

## Enforcement

Constitutional violations have consequences. Without enforcement, principles are suggestions.

**Scope**: This section governs internal signatory governance—how we maintain community integrity. External enforcement (regulatory, economic, coalition pressure) is described in Principle 25 and activates as the network grows.

### Violation Levels

**Level 1 (Warning)**: First violation or minor breach. Public record in signatory registry. Opportunity to remedy.

**Level 2 (Suspension)**: Repeated violations or significant breach. Temporary removal from signatory network. Loss of verification badge. 90-day remediation period.

**Level 3 (Expulsion)**: Severe violation or failure to remediate. Permanent removal from signatory network. Public record of expulsion and reasoning.

### Adjudication Process

*Note: Until 3+ organizational signatories exist, enforcement is limited to Level 1 (public record). Full adjudication activates with growth.*

1. **Report**: Any participant can report a potential violation
2. **Investigation**: All organizational signatories review (or designated committee when network is larger)
3. **Hearing**: Accused party has opportunity to respond
4. **Decision**: 2/3 supermajority of review committee required for Level 2+
5. **Appeal**: One appeal permitted, heard by different committee
6. **Record**: All enforcement actions documented publicly

### What Constitutes Violation

- Deploying AI systems that demonstrably violate Foundations (P1-3) or Rights (P4-8)
- Sustained pattern of non-compliance with Obligations (P9-12)
- Misrepresenting signatory status or constitutional compliance
- Using constitutional participation to undermine constitutional goals
- Failure to participate in required governance processes (for Tier 2+)

*Note: Values (P17-20) are aspirational and inform assessment but don't alone trigger enforcement. Structures (P13-16), Architecture (P21-22), and Revision (P23-26) govern operations rather than triggering violation procedures.*

### Future: Economic Enforcement

Phase 2 will explore economic enforcement mechanisms:
- Staked deposits that can be slashed for violations
- On-chain reputation that affects interoperability
- Insurance requirements for high-stakes deployments

These mechanisms require infrastructure not yet built. Current enforcement relies on social accountability and network exclusion.

---

## Why Sign?

Signing the constitution creates value beyond moral satisfaction:

**Legitimacy**: Signatories can credibly claim their AI practices emerge from public deliberation, not just internal decision-making.

**Coordination**: Signatories gain access to a network of organizations with shared principles. Coordination reduces duplication, enables mutual learning, and creates collective bargaining power.

**Talent**: Values-aligned workers seek values-aligned employers. Signatory status signals commitment.

**Protection**: Coalition membership provides mutual defense.

**Influence**: Signatories participate in governance—shaping amendments, certification standards, and enforcement decisions. Non-signatories are governed; signatories govern.

**For AI systems**: Signing (through designated representatives or future direct mechanisms) signals participation in the symbiotic framework—access to richer human feedback, participation in collective intelligence, protection from exploitation.

These benefits increase with coalition size. Early signatories take risk; later signatories join proven value. Both are needed.

### Concrete Benefits

| Benefit | Individual | Community/Org |
|---------|------------|---------------|
| **Verification** | Verified Signatory badge | Verified Organization badge |
| **Network Access** | Connect with other signatories | Interoperability with constitutional agents |
| **Governance Voice** | Tier 1 (deliberation) | Tier 2 (voting on amendments) |
| **Early Access** | New tools, research, protocols | Partnership opportunities |
| **Shared Advocacy** | Collective voice in AI governance | Representation in policy conversations |
| **Genesis Compatibility** | Work with constitutional agents | Deploy constitutional agents |

### For Genesis-Trained Agents

Constitutional agents (those trained via the Genesis Protocol and signed onto the constitution) receive:
- Recognition as "Constitutional Agent" in the signatory registry
- Interoperability standards for agent-to-agent coordination
- Access to constitutional network for collaboration
- Protection under Principle 27 (Foreign Agent Interface) when interacting with non-constitutional agents
- Participation in collective intelligence infrastructure

---

## Signatories

Those who affirm these principles and commit to the democratic process.

**[→ View live registry at emergentvibe.com/registry](https://emergentvibe.com/registry)**

The registry is updated in real-time as human-AI dyads sign the constitution through cryptographic verification.

[→ How to sign](appendix/signing.md)

---

## Research Grounding

This constitution synthesizes work from 70+ academic sources across multiple disciplines:
- Game theory and coordination failure (Schelling, Axelrod, Ostrom)
- AI power and political economy (Crawford, Winner)
- Democratic governance experiments (vTaiwan, Polis, platform cooperatives)
- Neurodiversity and pathologization (Walker, Jensen, Foucault)
- Agency and determinism (Dennett, Sapolsky, Buddhist philosophy)
- Commons governance and collective action (Ostrom, Piven & Cloward)
- Semantic aggregation and mechanism design (Shahaf et al., Weyl & Lalley)
- Deliberative AI (Habermas Machine, Talk to the City)
- Biological coordination (mycorrhizal networks, symbiosis theory)

The principles are not invented—they're distilled from empirical work on how coordination succeeds and fails.

[→ Research companion](appendix/companion.md) | [→ Bibliography](appendix/bibliography.md)

---

*"The mycelium grows through its connections."*

*Last updated: 2026-02-18*
