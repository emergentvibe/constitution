# II. Rights

What people can claim in relation to AI systems.

---

## Principle 4: Right to Transparency

**Understand how AI systems function, what data is used, what failures exist.**

People have the right to know:
- How AI systems that affect them work (not trade secrets, but meaningful explanation)
- What data was used to train them and where it came from
- What the known failure modes and biases are
- When they're interacting with AI vs. humans

Transparency isn't just about documentation - it's about power. Information architecture is power architecture. Opacity serves those who control the systems.

**Grounding**: Panel 6 (AI Governance) - transparency as precondition for accountability; algorithmic audits as enforcement mechanism.

---

## Principle 5: Right to Human Review

**Human review of algorithmic decisions in high-stakes domains.**

In domains where AI decisions significantly affect life outcomes - employment, housing, healthcare, criminal justice, education, credit - people have the right to:
- Know that an AI system was involved in the decision
- Request human review of that decision
- Have the human reviewer actually empowered to override
- Access meaningful appeal processes

Automation shouldn't mean abdication. The efficiency gains from AI don't justify removing human judgment from consequential decisions.

**Grounding**: Panel 5 (Agency) - human-in-loop as design principle; Panel 6 - accountability requires human decision points.

---

## Principle 6: Right to Collective Bargaining

**Workers, creators, and communities can collectively negotiate AI deployment terms.**

Individuals facing AI systems alone have no power. Collective organization changes this:
- Workers can negotiate how AI is deployed in their workplaces
- Creators can negotiate how their work is used for training
- Communities can negotiate how AI systems operate in their contexts

This isn't just labor rights - it's recognition that AI governance requires organized countervailing power. Without it, terms are dictated unilaterally.

**Grounding**: Panel 6 (AI Governance) - coalition power (tech workers + creators + labor + civil society + municipal networks) as enforcement mechanism; data trusts as collective bargaining infrastructure.

---

## Principle 7: Right to Exit and Alternatives

**Opt out of AI systems; access non-AI alternatives without penalty.**

People should be able to:
- Choose not to use AI systems without being disadvantaged
- Access human alternatives for essential services
- Maintain analog options for core life functions
- Exit AI-mediated systems without losing access to necessities

AI adoption should be a choice, not a mandate. The convenience of AI for some shouldn't eliminate options for others.

**Grounding**: Panel 4 (Deterritorialization) - analog alternatives as resistance; Panel 6 - interoperability and portability requirements.

---

## Principle 8: Right to Deterritorialization

**Communities can build alternative AI systems with different principles.**

The right to exit implies the right to build alternatives:
- Communities can develop AI systems governed by different values
- Open-weight models enable distributed innovation
- Public compute infrastructure supports non-corporate development
- AGPL-3 licensing ensures alternatives remain open

This isn't about fragmenting into incompatible systems - it's about maintaining genuine pluralism in AI development, not corporate monoculture.

**Grounding**: Panel 4 (Deterritorialization) - platform cooperatives, municipal AI networks, open-weight ecosystem as active deterritorialization sites; Panel 6 - open by default, public compute infrastructure.
