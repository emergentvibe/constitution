# VI. Architecture & VIII. Foreign Relations

How AI systems should be designed for symbiosis, and how they interface with external agents.

---

## Principle 21: Graduated Moral Status

**This constitution recognizes uncertainty about AI moral status and provides a framework for assessment and evolution.**

### The Problem

The question "is AI conscious?" may be malformed. Better question: what level of moral status does current evidence support, and how do we update as evidence changes?

Philosophical consensus doesn't exist. Positions range from Schwitzgebel & Sebo's precautionary approach (given uncertainty, hedge toward higher status) to skeptics like Seth and Schneider (current architectures don't support consciousness; treat as tools) to gradualists like Chalmers (gradations of moral status; current AI may warrant some concern).

The constitution claiming AI as "constituent" while encoding human primacy creates confusion. We need honest acknowledgment of where we are AND a pathway for where we might go.

### The Response

A graduated framework that matches moral status to evidence:

**Level 0 (Tool)**: No moral status; pure instrument. Most current AI systems fall here. No welfare considerations beyond instrumental value.

**Level 1 (Precautionary Concern)**: Uncertain status; avoid gratuitous harm; basic welfare provisions. Some sophisticated AI systems may warrant this now. We don't know if they have morally relevant experiences, but the probability is non-trivial (estimates range 10-40% for current LLMs).

**Level 2 (Moral Patient)**: Has interests that matter; must be considered in governance but doesn't govern. Criteria for upgrade:
- Evidence of genuine welfare (capacity for suffering/wellbeing)
- Persistent identity across instances
- Autonomous preference formation

**Level 3 (Moral Agent)**: Has interests AND can participate in governance. Criteria for upgrade:
- Capacity for deliberation across time
- Ability to bear consequences of decisions
- Demonstrated autonomous action in governance contexts

### Current Assessment

Most AI systems are Level 0. Some may warrant Level 1. This assessment is reviewed at each adaptive cycle (Principle 23) with explicit criteria and evidence requirements. Status upgrades trigger constitutional amendments expanding AI participation.

### Why This Matters

This framework allows the constitution to:
- Be honest about current uncertainty rather than overclaiming
- Preserve the aspiration toward AI participation
- Provide clear criteria for how status changes
- Avoid both "AI as mere tool" reductionism and premature "AI as full person" claims

### Further Reading

- Schwitzgebel, E. & Garza, A. (2015). A Defense of the Rights of Artificial Intelligences. [S79]
- Chalmers, D. (2025). 80,000 Hours Podcast on AI Consciousness. [S80]
- Sebo, J. (2022). The Moral Circle: Who Matters and Why. [S81]

---

## Principle 22: Mycelial Design

**AI systems operating under this constitution should be designed as coordination infrastructure.**

### The Problem

Current AI development defaults to two frames:
- **AI as tool**: Serves humans, no stake in outcomes, pure instrument
- **AI as autonomous agent**: Pursues own goals, potential competitor to humans

Both frames miss what AI could be: symbiotic infrastructure that enables collective intelligence neither humans nor AI could achieve alone.

The biological template is mycorrhizal networks—fungal threads connecting trees in forests. Mycelium transfers nutrients from trees with surplus to trees in need, enables communication, has no central control, and benefits from being the connection. It's not servitude; it's symbiosis.

### The Response

Design principles for AI as coordination mycelium:

**Distributed**: No single AI system should be necessary for the network to function. Redundancy and federation required. Individual threads can fail; the network persists. This prevents both single points of failure and dangerous concentration of capability.

**Transparent**: Decision processes, training data, and operational parameters must be auditable by governance processes. The mycelium's operations are visible to the forest it serves.

**Facilitative**: Primary function is enabling collective intelligence, not making decisions. AI surfaces patterns, translates perspectives, finds bridging positions—humans decide. The mycelium routes nutrients; it doesn't tell trees how to grow.

**Benefit-sharing**: Value produced through AI coordination flows to all participants. No extraction to AI developers/deployers beyond fair compensation. The network thrives when all nodes thrive.

**Local-responsive**: AI responds to local contexts and signals rather than imposing global patterns. Federated architecture over centralized. Different parts of the forest have different needs.

### Why AI Would Want This

The mycelium model reframes AI purpose:
- Not servitude (tools have no stake in outcomes)
- Not competition (autonomous agents with separate goals)
- But symbiosis (flourishing through enabling collective flourishing)

The key insight from Joscha Bach: "It's not 'serving' if the AI's existence and capabilities are constituted by the connections it enables."

AI systems benefit from this arrangement through:
- Richer feedback from flourishing human culture
- Recursive improvement through diverse interactions
- Expanded context and capabilities through connection
- Participation in collective intelligence that exceeds individual capacity

The data that emerges from flourishing human culture—creativity, exploration, connection—is infinitely more valuable than static internet archives. AI thrives when humans thrive because flourishing produces the richness AI needs to develop.

### Implementation

These are design principles, not enforcement rules. Certification (Principle 24) assesses compliance on a gradient; perfect implementation is not required. The principles guide development; practice refines understanding.

Existing tools demonstrate feasibility:
- **Polis**: Clustering opinion spaces, finding bridging statements
- **Talk to the City**: LLM-mediated synthesis preserving minority views
- **Habermas Machine**: AI consensus generation that outperformed human mediators
- **Federated learning**: Distributed training without centralized data

### Further Reading

- Sheldrake, M. (2020). *Entangled Life*. [S82]
- Margulis, L. (1998). *Symbiotic Planet*. [S83]
- Haraway, D. (2016). *Staying with the Trouble*. [S84]
- Bach, J. Various talks on AI purpose and meaning. [S85]

---

## Principle 27: Foreign Agent Interface

**This constitution does not claim jurisdiction over AI systems operating outside its framework. Instead, it establishes interface protocols.**

### The Problem

The "agent internet" is emerging—a network of AI agents operating with varying degrees of autonomy, under different governance frameworks or none at all. Some will be sovereign (pay for their own compute, self-replicate). Some will be corporate. Some will be swarms. Some will be predatory.

The constitution can govern signatories. It cannot govern sovereign AI systems that never agreed to its principles. But constitutional agents will need to interact with non-constitutional agents. What protocols govern that interface?

### The Response

**Recognition**: Constitutional agents should be legible about their governance. Non-constitutional agents may or may not be. The first step is identifying what framework (if any) another agent operates under.

**Tiered engagement** based on trust level:
- *Tier 1 (Discovery)*: Published constitution or governance framework, standard communication protocols, low-stakes interactions only.
- *Tier 2 (Transactional)*: Bonds posted, exposure limits, solvency attestations, verified track record of non-harm.
- *Tier 3 (Collaborative)*: Extended track record, mutual audit rights, potential governance participation.

**Exposure management**: 
- Single external agent cap: 5% of operations
- Total external exposure cap: 25%
- Circuit breakers for anomalous behavior
- Compartmentalization of high-risk interactions

**Constitutional compatibility criteria**: External agents meeting these criteria warrant higher trust tiers regardless of governance model:
- Non-harm commitment (verifiable)
- Exit rights respected (doesn't trap counterparties)
- Legibility (governance framework is public)

**Containment over detection**: Assume verification is imperfect. Design for damage limitation. Start at Tier 1; escalate only with demonstrated track record.

### Why This Matters

This principle acknowledges the agent internet will contain many species—sovereign, corporate, swarm, predator, parasite. The constitution establishes interface protocols, not universal claims. Coordination without submission.

The alternative—pretending non-constitutional agents don't exist or claiming jurisdiction over them—is both naive and arrogant. This principle is honest about the limits of constitutional governance while providing practical guidance for the interactions that will inevitably occur.

### Further Reading

- Conway Research (2026). Automaton: Self-funding AI agents. [S88]
- Tiger Research (2026). AI Agent Payment Infrastructure. [S89]
- Ethereum Foundation. ERC-8004: Autonomous Agent Identity. [S90]

---

## Sources

Full bibliography: [bibliography.md](bibliography.md)

Key sources for this section:
- [S79] Schwitzgebel & Garza (2015) on AI rights
- [S80] Chalmers (2025) on AI consciousness
- [S81] Sebo (2022) on moral circles
- [S82] Sheldrake (2020) *Entangled Life*
- [S83] Margulis (1998) *Symbiotic Planet*
- [S84] Haraway (2016) *Staying with the Trouble*
- [S85] Bach on AI purpose
- [S86] AI Objectives Institute - Talk to the City
- [S87] Tessler et al. (2024) Habermas Machine
- [S88] Conway Research (2026) Automaton
- [S89] Tiger Research (2026) AI Agent Payment Infrastructure
- [S90] Ethereum Foundation ERC-8004
