# Research Companion

*The reasoning behind the Emergent Vibe Constitution*

---

## Executive Summary

This constitution emerges from a simple observation: **the rules governing AI development are currently set by a handful of companies optimizing for shareholder value**. We believe these rules should emerge from collective deliberation by the people who will live with AI.

But "collective deliberation" isn't enough. We needed to understand:
- Why current systems fail
- What theoretical frameworks illuminate the problem
- What historical evidence shows about change
- What concrete governance mechanisms might work

This research companion explains how we got from questions to principles.

---

## The Problem

### 1. Attention Capture and Hybrid Selfhood

AI systems are co-authoring who we become. Through algorithmic attention management, recommendation systems, and personalized content, digital environments shape perception, memory, and identity formation.

This isn't neutral augmentation—it's **adversarial coupling**. Systems optimized to capture attention exploit cognitive vulnerabilities. The result: hybrid selves with degraded autonomy, outsourced judgment, and atrophied capabilities.

*Key sources: Crawford (S25), Morton (S32), Pew Research (S62)*

### 2. Moloch Dynamics and Coordination Failure

Even when everyone sees the problem, coordination failures prevent solutions. Each company captures attention because competitors do. Each institution pathologizes variation because others do. Individual rationality produces collective disaster.

Scott Alexander's "Meditations on Moloch" (S17) names this: multipolar traps where no one can unilaterally defect to cooperation. The game theory is clear—we're in a Nash equilibrium that hurts everyone.

*Key sources: Alexander (S17), Schelling (S18-19), Axelrod (S20), Yudkowsky (S24)*

### 3. Power Concentration

AI development is concentrated in a handful of companies with:
- 90%+ of compute resources
- Proprietary training data
- Closed model weights
- Opaque decision-making

This concentration isn't accidental—it reflects network effects, economies of scale, and regulatory capture. But it's also not inevitable. Alternative architectures exist.

*Key sources: Crawford (S25-26), Winner (S36), DeepSeek/Qwen developments (S65)*

### 4. Timeline Uncertainty

We don't know how long we have. Pessimists argue 5-15 years to lock-in; optimists argue 20-50 years for cultural evolution to catch up. Both scenarios are plausible. We won't know which is right until it's too late.

This uncertainty argues for **urgency on high-leverage interventions** combined with **robust strategies that work in either timeline**.

*Key sources: Bostrom (S27-29), Pérez (S30-31), Perreault (S33)*

---

## Theoretical Frameworks

### Superorganisms and Collective Entities

Human societies exhibit superorganism-like properties: multilevel selection, functional organization through feedback loops, emergent behavior not reducible to individual intentions. We're not strict superorganisms (no unified intentionality), but superorganism thinking illuminates how collectives "self" individuals.

What gets labeled "disorder" is often sociobiological mismatch—attention calibrated for different scales, social processing tuned for different contexts. Pathologization serves system stability, not individual flourishing.

*Key sources: E.O. Wilson (S1-2), D.S. Wilson (S3-5), DeLanda (S6-7)*

### Assemblage Theory

Systems don't "want" things, but they have **tendencies**: territorialization, extraction, concentration, acceleration. These emerge from distributed interactions shaped by economic incentives, technical affordances, and power relations.

Assemblages can also **deterritorialize**—escape established patterns through lines of flight. Change happens not by controlling systems but by participating in their composition.

*Key sources: DeLanda (S6-7), Deleuze & Guattari (S56)*

### Game Theory and Mechanism Design

Coordination failures are Nash equilibria—stable because no one can unilaterally defect. Shifting equilibria requires:
- Focal points (clear standards everyone can coordinate around)
- Changing payoffs (make cooperation cheaper, defection expensive)
- Expectation cascades (enough actors moving that others follow)
- Shadow of the future (repeated games where reputation matters)

*Key sources: Schelling (S18-19), Axelrod (S20), Maynard Smith (S21-22), Gintis (S23)*

### Capabilities Approach

Flourishing isn't efficiency. It's expanding human capabilities: practical reason, affiliation, imagination, emotions, play, control over environment. Systems that optimize humans for institutional fit fail this test even if they "work."

*Key source: Nussbaum (referenced via Panel 5)*

### Commons Governance

Elinor Ostrom showed that commons can be successfully governed without privatization or state control. Eight design principles from 800+ empirical cases:
1. Clear boundaries
2. Congruence with local conditions
3. Collective-choice arrangements
4. Monitoring by community
5. Graduated sanctions
6. Conflict resolution
7. Recognition of rights to organize
8. Nested enterprises

These principles inform our governance structures.

*Key source: Ostrom (S40)*

---

## Historical Evidence

### Timelines for Major Transitions

| Transition | Duration | Key Mechanisms |
|------------|----------|----------------|
| Slavery abolition | 50-80 years | Economic shifts, moral framing, legal focal points |
| LGBTQ+ rights (Stonewall → Obergefell) | 46 years | Disruption, legal strategy, cultural representation |
| Disability rights (organizing → ADA) | 20+ years | Capitol Crawl, legal focal points, coalition building |
| Neurodiversity movement | Ongoing | Growing influence but increasing cooptation |

### What Worked

Historical movements succeeded through **multiple reinforcing mechanisms**:
- **Disruption** (Stonewall, ACT UP, Capitol Crawl)
- **Legal strategy** (focal points like ADA, expert testimony)
- **Cultural shift** (representation, moral framing, historical argument)
- **Material base** (resources, infrastructure, sustainable funding)
- **Crisis acceleration** (AIDS, COVID)

No single mechanism was sufficient. All were necessary.

*Key sources: Piven & Cloward (S37), Chauncey (S38-39), ADA (S44)*

### Cooptation Risk

Every successful movement faces capture. The neurodiversity movement provides a contemporary example: growing influence but increasing corporate cooptation. Workplace postings mentioning neurodiversity tripled 2018-2024, but material conditions haven't improved proportionally.

Cooptation resistance requires ongoing vigilance, not one-time solutions.

*Key sources: Walker (S45), Neurodiversity as Politics (S46)*

---

## How Principles Emerged

### Section I: Foundations

**Principle 1 (Human Agency Preservation)** emerged from Panel 5's analysis of agency under determinism. All major philosophical frameworks—hard determinism, compatibilism, Buddhist no-self, Bourdieu's habitus—converge on the importance of preserving human judgment capacity even if we lack libertarian free will.

**Principle 2 (Collective Governance)** emerged from Panel 6's analysis of vTaiwan and existing democratic AI initiatives. Democratic governance isn't just ethically preferable—it produces better outcomes through distributed knowledge aggregation.

**Principle 3 (Plurality and Accommodation)** emerged from Panel 1's analysis of how superorganisms "self" individuals. Pathologization serves system stability, not individual flourishing. Accommodation expands the range of viable ways to be human.

### Section II: Rights

**Principles 4-8** operationalize the theoretical insights as individual protections. Transparency (P4) addresses information asymmetry. Human review (P5) preserves judgment capacity. Collective bargaining (P6) provides countervailing power. Exit rights (P7-8) maintain alternatives.

These aren't just aspirations—they're enforceable claims that shift power.

### Section III: Obligations

**Principles 9-12** create accountability structures. Impact assessment (P9) addresses the speed mismatch between AI development and institutional adaptation. Recursion safeguards (P10) maintain human discriminator function. Liability (P11) creates incentives for safety. Openness (P12) enables oversight.

### Section IV: Structures

**Principles 13-16** specify governance architecture. Federated governance (P13) resolves the local-vs-global tension through layered scales. Commons-based ownership (P14) provides material alternatives. Hybrid expertise (P15) balances technical knowledge with democratic legitimacy. Parliament of Things (P16) extends moral consideration beyond present adult humans.

### Section V: Capabilities

**Principles 17-20** define what AI development should optimize for. Flourishing over efficiency (P17). Care as commons (P18). Weird and unexpected (P19). Contemplative capacity (P20). These resist the reduction of human value to productivity.

### Section VI: Revision and Enforcement

**Principles 21-24** make the constitution a living document with teeth. Regular amendment (P21). Certification (P22). Multiple enforcement mechanisms (P23). Coalition power (P24). Architecture alone is insufficient—organized people make rules real.

---

## Key Tensions (Unresolved)

### T9: Timeline Uncertainty

5-15 years to lock-in (pessimist) vs 20-50 years for cultural evolution (optimist). We don't know which is right. This argues for urgency + robustness.

### T15: Cooptation Resistance

Every movement faces capture. We know cooptation happens but don't have reliable mechanisms to prevent it. Ostrom's principles provide framework, not guarantee.

### T19: Parliament of Things Implementation

How do we ACTUALLY include non-human stakeholders institutionally? The principle establishes direction; mechanisms remain unclear.

### Mirowski's Critique

Is "democratic AI" conceptually distinct from neoliberalized participation? Every reform movement gets captured. What makes this different? Tension between optimists (marginally but meaningfully better) and skeptics (sophisticated rationalization).

---

## Call to Action

This constitution isn't self-implementing. It requires:

1. **Ratification** through collective deliberation
2. **Coalition building** across tech workers, creators, labor, civil society, municipal networks
3. **Material infrastructure** (municipal AI, public compute, data trusts)
4. **Ongoing revision** as we learn what works

The cyborg superorganism goes where we compose it. Not through deterministic control but through participating in its becoming.

Three trajectories are possible: dystopian lock-in, muddled contested present, democratic breakthrough. Which we get depends on what we do in the next 5-10 years.

**Build.**

---

## Further Reading

- **Full investigation**: `memetic-self/.ai-symposium/investigations/superorganism-selves/`
- **Bibliography**: `bibliography.md`
- **Panel summaries**: `INVESTIGATION-2-COMPLETE.md`
- **95 recommendations**: `artifacts/recommendations.json`
- **27 tensions**: `artifacts/tensions.json`

---

*This document summarizes research conducted through the ai-symposium multi-panel deliberation framework. 7 panels, 46 experts consulted, 80 academic sources, 95 recommendations synthesized.*
